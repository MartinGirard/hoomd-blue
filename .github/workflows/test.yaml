name: Test

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

on:
  pull_request:
      types: [opened, labeled, reopened, synchronize]

  push:
    branches:
    - "trunk-*"

  workflow_dispatch:

jobs:
  start_action_runners:
    name: Start
    uses: glotzerlab/jetstream2-admin/.github/workflows/start.yaml@c89b62aa89f7886318edb166bc0500cfc658f24f # v1.3.0
    secrets: inherit

  typical:
    name: "${{ join(matrix.config, '_') }}"
    needs: start_action_runners
    uses: ./.github/workflows/build_and_test.yaml
    with:
      config: ${{ join(matrix.config, '_') }}
      image: glotzerlab/ci:2024.06.04-${{ matrix.config[0] }}
      # Use self-hosted runners or fall back to GitHub hosted runners when self-hosted are offline
      build_runner: ${{ needs.start_action_runners.outputs.active == '0' && toJson('ubuntu-latest') || '["self-hosted","jetstream2","CPU"]' }}
      # Default to ubuntu-latest when unset
      test_runner: ${{ matrix.test_runner == '' && toJson('ubuntu-latest') || toJson(matrix.test_runner) }}
      test_docker_options: ${{ matrix.test_docker_options }}
      # Default to false when unset
      validate: ${{ matrix.validate == '' && 'false' || matrix.validate }}

    strategy:
      fail-fast: false
      matrix:
        include:
        - config: [clang18_py312, mpi, tbb]
          validate: 'true'

        - config: [gcc13_py312]
          validate: 'true'

        - config: [cuda120_gcc11_py310, mpi, llvm]
          test_runner: [self-hosted,GPU]
          test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl'
          validate: 'true'

        - config: [cuda120_gcc11_py310]
          test_runner: [self-hosted,GPU]
          test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl'
          validate: 'true'

        - config: [gcc14_py312, nomd]

        - config: [gcc14_py312, nohpmc]

        - config: [gcc14_py312, nomd, nohpmc]

        - config: [cuda120_gcc11_py310, mpi, llvm, debug]
          test_runner: [self-hosted,GPU]
          test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl'

        - config: [gcc9_py39]

  release:
    if: ${{ contains(github.event.pull_request.labels.*.name, 'release') }}
    name: "${{ join(matrix.config, '_') }}"
    needs: start_action_runners
    uses: ./.github/workflows/build_and_test.yaml
    with:
      config: ${{ join(matrix.config, '_') }}
      image: glotzerlab/ci:2024.06.04-${{ matrix.config[0] }}
      # Use self-hosted runners or fall back to GitHub hosted runners when self-hosted are offline
      build_runner: ${{ needs.start_action_runners.outputs.active == '0' && toJson('ubuntu-latest') || '["self-hosted","jetstream2","CPU"]' }}
      # Default to ubuntu-latest when unset
      test_runner: ${{ matrix.test_runner == '' && toJson('ubuntu-latest') || toJson(matrix.test_runner) }}
      test_docker_options: ${{ matrix.test_docker_options }}
      # Default to false when unset
      validate: ${{ matrix.validate == '' && 'false' || matrix.validate }}

    strategy:
      fail-fast: false
      matrix:
        include:
        - config: [clang18_py312, mpi]
        - config: [clang17_py312, mpi]
        - config: [clang16_py312, mpi, llvm]
        - config: [clang15_py312, mpi, llvm]
        - config: [clang14_py311, mpi, tbb, llvm]
        - config: [clang13_py310, llvm]
        - config: [clang12_py310, llvm]
        - config: [clang11_py310, llvm]
        - config: [gcc13_py312, mpi]
        - config: [gcc12_py311]
        - config: [gcc11_py310]
        - config: [gcc10_py310]
        - config: [cuda118_gcc11_py310, mpi, llvm]
          test_runner: [self-hosted,GPU]
          test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl'

        - config: [cuda117_gcc11_py310, mpi, llvm]
          test_runner: [self-hosted,GPU]
          test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl'

  build:
    runs-on: ubuntu-latest
    steps:
    - name: Check out repo
      uses: actions/checkout@a5ac7e51b41094c92402da3b24376905380afc29 # v4.1.6
      with:
        submodules: true
    - name: Set up Python
      uses: actions/setup-python@82c7e631bb3cdc910f68e0081d67478d79c6982d # v5.1.0
      with:
        python-version: "3.12"
    - name: Setup uv
      uses: glotzerlab/workflows/setup-uv@5cfac9da9cb78e16ae97a9119b6fd13c1c2d6f5e # 0.1.0
    - name: Install dependencies
      run: uv pip install -r sphinx-doc/requirements.txt --system
    - name: Verify pandoc installation
      run: pandoc --version
    - name: Build Sphinx Docs
      run: sphinx-build -b html sphinx-doc doc_build
    - name: Link Checker
      id: lychee
      uses: lycheeverse/lychee-action@v1

  tests_complete:
    name: Unit test
    if: always()
    needs: [typical]
    runs-on: ubuntu-latest

    steps:
    - run: jq --exit-status 'all(.result == "success")' <<< '${{ toJson(needs) }}'
    - name: Done
      run: exit 0
